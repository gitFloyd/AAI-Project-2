# -*- coding: utf-8 -*-
"""Pistachio Detection CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/gitFloyd/AAI-Project-3/blob/main/Classification_of_images_of_Pistacio_using_CNN_v1.ipynb
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

#Directory to dataset in drive

image_size = (150,150)
batch_size = 10
dataset_path ='D:\Google Drive\Kent\Kent 2022-1 Spring\Artificial Intelligence\Project 3\datasets\Pistachio_Image_Dataset\Pistachio_Image_Dataset - small'
#Data Generators 

train_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)

train_g = train_gen.flow_from_directory(
    directory = dataset_path,
    target_size = image_size,
    batch_size = batch_size,
    class_mode = "binary",
    subset = "training")
val_g = train_gen.flow_from_directory(
    directory = dataset_path,
    target_size = image_size,
    batch_size = batch_size,
    class_mode = "binary",
    subset = "validation"
)

def plotImages (images_arr):
  fig,axes = plt.subplots(1,5)
  axes = axes.flatten()
  for img, ax in zip(images_arr,axes):
    ax.imshow(img)
    ax.axis('off')
    plt.tight_layout()
    plt.show()

imgs,labels = next(train_g)
plotImages(imgs)
print(labels[:5])

#Verify data
class_names = ['Kirmizi', 'Siirt']
img,lab = next(train_g)

plt.figure(figsize=(10,10))
for i in range(10):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(img[i])
    plt.xlabel(class_names[lab[i].astype('int32')])
plt.show()

#create model
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.summary()

#Add dense layer
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))

model.summary()

#Compile and train the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=["accuracy"])

model.summary()

history = model.fit(train_g,
                    epochs = 10,
                    verbose=1,
                    validation_data=val_g)

#Evaluate the model
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(val_g, verbose=2)

print(test_acc)

